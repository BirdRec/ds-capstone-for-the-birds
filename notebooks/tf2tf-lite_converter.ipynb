{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TensorFlow models to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "[1] [https://www.tensorflow.org/lite/models/convert/](https://www.tensorflow.org/lite/models/convert/)\n",
    "\n",
    "[2] [https://www.tensorflow.org/lite/models/convert/convert_models](https://www.tensorflow.org/lite/models/convert/convert_models)\n",
    "\n",
    "[3] [https://www.tensorflow.org/lite/performance/post_training_quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\n",
    "\n",
    "[4] [https://www.tensorflow.org/lite/guide/inference](https://www.tensorflow.org/lite/guide/inference)\n",
    "\n",
    "[5] [https://www.tensorflow.org/lite/performance/model_optimization](https://www.tensorflow.org/lite/performance/model_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get overview of provided models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current absolute path of parent folder of this file\n",
    "path_notebooks = os.path.dirname(os.path.abspath('tf2tf-lite_converter'))\n",
    "\n",
    "# Get path of parent directory, i.e. path to repo\n",
    "path = os.path.abspath(os.path.join(path_notebooks, os.pardir))\n",
    "\n",
    "# list available models stored in 'saved_model' (without hidden folders)\n",
    "x = os.listdir(path + '/saved_model')\n",
    "x = [i for i in x if not i.startswith('.')]\n",
    "print(*x, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select model to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which saved model to convert\n",
    "model = 'MobileNetV3_Kaggle_p150_e10'\n",
    "\n",
    "# Set path to saved model directory\n",
    "saved_model_dir = os.path.abspath(path + '/saved_model/' + model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute model conversion to TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] # Dynamic range quantization (4x smaller, 2x-3x speedup, smallest accuracy loss)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "path_save = 'saved_model_tf-lite/' + model + '_dr-quant' + '.tflite'\n",
    "with open(path_save, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99cf74314b42ac8a8c1da03c92f17d43111865473f1a5aa1cc3b81d76b6237d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

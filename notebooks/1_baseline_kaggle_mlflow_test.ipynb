{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model with Kaggle data: 2 epochs and 100x100 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pathlib, os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import mlflow\n",
    "\n",
    "#from modeling.config import EXPERIMENT_NAME\n",
    "from config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current absolute path of parent folder of this file\n",
    "path_notebooks = os.path.dirname(os.path.abspath('1_baseline_kaggle_mlflow_test'))\n",
    "\n",
    "# Get path of parent directory, i.e. path to repo\n",
    "path = os.path.abspath(os.path.join(path_notebooks, os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'kaggle' # or 'kaggle+europe' or 'europe'\n",
    "\n",
    "train_dir = path + '/data/data_2/train/'\n",
    "test_dir = path + '/data/data_2/test/'\n",
    "val_dir = path + '/data/data_2/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(path + \"/data/data_2/train/\")\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # creating a list of class names from subdirectory \n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = class_names[1:]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "  # setting up the image directory\n",
    "  target_folder = target_dir + target_class\n",
    "\n",
    "  #get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  #read image and plotting it\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0] )\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\")\n",
    "  \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = view_random_image(target_dir = train_dir,\n",
    "                        target_class = '/BAY-BREASTED WARBLER'\n",
    "                        ) # or we can write nike instead of converse to see converse examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape #(width, height, colour channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "plt.subplot(1,3,1)\n",
    "steak_image = view_random_image(train_dir, \"/BAR-TAILED GODWIT\")\n",
    "plt.subplot(1,3,2)\n",
    "pizza_image = view_random_image(train_dir, \"/YELLOW HEADED BLACKBIRD\")\n",
    "plt.subplot(1,3,3)\n",
    "pizza_image = view_random_image(train_dir, \"/INDIAN PITTA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# Rescale\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# data transfer from directories to batches\n",
    "train_data = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                               batch_size= BATCH_SIZE,\n",
    "                                               target_size= (IMG_HEIGHT,IMG_WIDTH),\n",
    "                                               class_mode = \"categorical\")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               target_size = (IMG_HEIGHT,IMG_WIDTH),\n",
    "                                               class_mode = \"categorical\")\n",
    "\n",
    "val_data = valid_datagen.flow_from_directory(directory = val_dir,\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               target_size = (IMG_HEIGHT,IMG_WIDTH),\n",
    "                                               class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Creating and fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a base model with tf.keras.applications\n",
    "base_model = tf.keras.applications.InceptionV3(include_top= False,)\n",
    "\n",
    "# 2. Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "#3. Create inputs into models\n",
    "inputs = tf.keras.layers.Input(shape =(IMG_HEIGHT,IMG_WIDTH,3), name = \"input-layer\")\n",
    "\n",
    "#4. Rescaling\n",
    "#x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)(inputs)\n",
    "\n",
    "#5. Pass the inputs \n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 6. Average pool the outputs of the base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name = \"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "#7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(450, activation = \"softmax\", name = \"output-layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Combine the inputs with outputs into a model\n",
    "LEARNING_RATE = 0.03\n",
    "model_p100_e2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile the model\n",
    "model_p100_e2.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n",
    "                metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='base model test')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "history = model_p100_e2.fit(train_data,\n",
    "                                 epochs=EPOCHS,\n",
    "                                 steps_per_epoch = len(train_data),\n",
    "                                 validation_data = val_data,\n",
    "                                 validation_steps = int(0.25*len(val_data)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model, history and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime info: One epoch with the res takes roughly 4-5 minutes - total runtime:27 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire small model as a SavedModel.\n",
    "#!mkdir -p saved_model\n",
    "\n",
    "model_name = 'baseline_kaggle_p100_e2'\n",
    "model_p100_e2.save(path + '/saved_model/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "with open(path + '/saved_model/' + model_name + '/trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {}\n",
    "param_dict['ds'] = DATASET\n",
    "param_dict['lr'] = LEARNING_RATE\n",
    "param_dict['bs'] = BATCH_SIZE\n",
    "param_dict['eps'] = EPOCHS\n",
    "param_dict['img_height'] = IMG_HEIGHT\n",
    "\n",
    "# save model parameters\n",
    "with open(path + '/saved_model/' + model_name + '/trainParamsDict', 'wb') as file_pi:\n",
    "    pickle.dump(param_dict, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p100_e2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p100_e2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "\n",
    "  loss = history.history[\"loss\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "  accuracy = history.history[\"accuracy\"]\n",
    "  val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "  epochs = range(len(history.history[\"loss\"]))\n",
    "\n",
    "  #plot loss\n",
    "  plt.plot(epochs, loss, label = \"training_loss\")\n",
    "  plt.plot(epochs, val_loss, label = \"val_loss\")\n",
    "  plt.title(\"loss\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()\n",
    "\n",
    "  #plot accuracy\n",
    "  plt.figure() \n",
    "  plt.plot(epochs, accuracy, label = \"training_accuracy\")\n",
    "  plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n",
    "  plt.title(\"accuracy\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seting parameters that should be logged on MLFlow\n",
    "#these parameters were used in feature engineering (inputing missing values)\n",
    "#or parameters of the model (fit_intercept for Linear Regression model)\n",
    "params = {\n",
    "      \"batch_size\": BATCH_SIZE,\n",
    "      \"image_size\": IMG_HEIGHT,\n",
    "      \"epochs\": EPOCHS,\n",
    "      \"learning_rate\": LEARNING_RATE,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "#setting tags\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"True\")\n",
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][-1])\n",
    "mlflow.log_metric(\"valid-\" + \"accuracy\", history.history['val_accuracy'][-1])\n",
    "mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][-1])\n",
    "mlflow.log_metric(\"valid-\" + \"loss\", history.history['val_loss'][-1])\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.keras.log_model(model_p100_e2 ,'InceptionV3')\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Freeze top layers of Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To begin fine-tuning lets start by setting the last 10 layers as trainable\n",
    "base_model.trainable = True\n",
    "\n",
    "# Un-freeze last 10 layers\n",
    "for layer in base_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile (we have to compile model every time there is a change)\n",
    "model_p100_e5.compile(loss = \"categorical_crossentropy\",\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), # when fine-tuning you typically want to lower lr by 10x\n",
    "                 metrics = [\"accuracy\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which layers are trainable\n",
    "for layer_number, layer in enumerate(model_p100_e5.layers[1].layers):\n",
    "  print(layer_number, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have unfrozen some of the layers on the top \n",
    "print(len(model_p100_e5.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-Tuning and Refitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 5\n",
    "fine_tune_epochs = initial_epochs + 1\n",
    "\n",
    "# Refit the model\n",
    "history_2 = model_p100_e5.fit(train_data,\n",
    "                       epochs = fine_tune_epochs,\n",
    "                       validation_data = val_data,\n",
    "                       validation_steps = int(0.25*len(val_data)),\n",
    "                       initial_epoch =  history.epoch[-1],) # Start the epoch where it left before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p100_e5.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire small model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model_p100_e5.save('saved_model/model_p100_e5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: \n",
    "# img_height = 200\n",
    "# img_width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cReating a function that preprocess the custom data\n",
    "\n",
    "def load_and_prep_image(filename, img_shape = img_height):\n",
    "  img = tf.io.read_file(filename) #read image\n",
    "  img = tf.image.decode_image(img) # decode the image to a tensor\n",
    "  img = tf.image.resize(img, size = [img_height, img_width]) # resize the image\n",
    "  img = img/255. # rescale the image\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot(model, filename, class_names):\n",
    "  \"\"\"\n",
    "  Imports an image located at filename, makes a prediction on it with\n",
    "  a trained model and plots the image with the predicted class as the title.\n",
    "  \"\"\"\n",
    "  # Import the target image and preprocess it\n",
    "  img = load_and_prep_image(filename)\n",
    "\n",
    "  # Make a prediction\n",
    "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "  # Get the predicted class\n",
    "  if len(pred[0]) > 1: # check for multi-class\n",
    "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
    "  else:\n",
    "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
    "\n",
    "  # Plot the image and predicted class\n",
    "  plt.imshow(img)\n",
    "  plt.title(f\"Prediction: {pred_class}\")\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new files to the test folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsel = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/Amsel.jpeg\"\n",
    "blaumeise = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/blaumeise.jpeg\"\n",
    "buchfink = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/buchfink.jpeg\"\n",
    "elster = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/elster.jpeg\"\n",
    "feldsperling = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/feldsperling.jpeg\"\n",
    "firefinch = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/firefinch.jpg\"\n",
    "gruenfink = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/gr√ºnfink.jpeg\"\n",
    "haussperling = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/haussperling.jpeg\"\n",
    "kohlmeise = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/Kohlmeise.jpeg\"\n",
    "mauersegler = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/mauersegler.jpeg\"\n",
    "mehlschwalbe = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/mehlschwalbe.jpeg\"\n",
    "rotkehlchen = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/Rotkehlchen.jpeg\"\n",
    "star = \"/Users/friederikethies/neue_fische/ds-capstone-for-the-birds/data_2/images to test/Star.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(model_p100_e5, amsel, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99cf74314b42ac8a8c1da03c92f17d43111865473f1a5aa1cc3b81d76b6237d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

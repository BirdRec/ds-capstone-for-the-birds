{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2/V3Large Model with Kaggle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source of dataset: [https://www.kaggle.com/datasets/gpiosenka/100-bird-species](https://www.kaggle.com/datasets/gpiosenka/100-bird-species)\n",
    "\n",
    "References used within this notebook:\n",
    "- [1] [https://www.tensorflow.org/tutorials/images/classification](https://www.tensorflow.org/tutorials/images/classification)\n",
    "- [2] [https://www.tensorflow.org/tutorials/load_data/images](https://www.tensorflow.org/tutorials/load_data/images)\n",
    "- [3] [https://keras.io/api/applications/#usage-examples-for-image-classification-models](https://keras.io/api/applications/#usage-examples-for-image-classification-models)\n",
    "- [4] [https://www.kaggle.com/code/abduulrahmankhalid/birds-species-prediction-mobilenetv2-acc-95](https://www.kaggle.com/code/abduulrahmankhalid/birds-species-prediction-mobilenetv2-acc-95)\n",
    "- [5] [https://keras.io/guides/transfer_learning/](https://keras.io/guides/transfer_learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Content\n",
    "### 1) Get data insights\n",
    "### 2) Train the model\n",
    "### 3) Evaluation\n",
    "### 4) Save model, history and parameters\n",
    "### 5) Retrain model\n",
    "### 6) Making some predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get data insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import mlflow\n",
    "\n",
    "#from modeling.config import EXPERIMENT_NAME\n",
    "from config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'europe' # or 'kaggle+europe' or 'europe'\n",
    "\n",
    "# Get current absolute path of parent folder of this file\n",
    "path_notebooks = os.path.dirname(os.path.abspath('mlflow_3_MobileNetV2_Kaggle_finetuned'))\n",
    "\n",
    "# Get path of parent directory, i.e. path to repo\n",
    "path = os.path.abspath(os.path.join(path_notebooks, os.pardir))\n",
    "\n",
    "train_dir = path + '/data/europe/train/'\n",
    "val_dir = path + '/data/europe/valid/'\n",
    "test_dir = path + '/data/europe/test/'\n",
    "\n",
    "# create pathlib object from string train_dir (path to train directory)\n",
    "train_dir_pl = pathlib.Path(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many training images do we have?\n",
    "image_count = len(list(train_dir_pl.glob('*/*.jp*')))\n",
    "print(f'Number of training samples: {image_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data using a Keras utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                      color_mode='rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      label_mode = 'categorical',\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                      seed=None,\n",
    "                                                      validation_split=None,\n",
    "                                                      crop_to_aspect_ratio=True,\n",
    "                                                      interpolation='bilinear')\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(val_dir,\n",
    "                                                      color_mode='rgb',\n",
    "                                                      label_mode ='categorical',\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                      seed=None,\n",
    "                                                      validation_split=None,\n",
    "                                                      crop_to_aspect_ratio=True,\n",
    "                                                      interpolation='bilinear')\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
    "                                                      color_mode='rgb',\n",
    "                                                      label_mode ='categorical',\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                      seed=None,\n",
    "                                                      validation_split=None,\n",
    "                                                      crop_to_aspect_ratio=True,\n",
    "                                                      interpolation='bilinear')                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First visual impression\n",
    "- using PIL (python image library) for first two images\n",
    "- using matplotlib.image for two additional images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of paths to all birds of class 'ABBOTTS BABBLER' and show first two birds\n",
    "abbotts_babbler = list(train_dir_pl.glob('ABBOTTS BABBLER/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = PIL.Image.open(str(abbotts_babbler[0]))\n",
    "print(f\"Image shape: {img1.size}\")\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = PIL.Image.open(str(abbotts_babbler[1]))\n",
    "print(f\"Image shape: {img2.size}\")\n",
    "img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is taken from [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "  # setting up the image directory\n",
    "  target_folder = target_dir + target_class\n",
    "\n",
    "  #get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  #read image and plotting it\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0] )\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\")\n",
    "  \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = view_random_image(target_dir = train_dir,\n",
    "                        target_class = '/BAY-BREASTED WARBLER'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = view_random_image(target_dir = train_dir,\n",
    "                        target_class = '/GOLDEN EAGLE'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    #plt.title(class_names[labels[i]])\n",
    "    plt.title(class_names[labels[i].numpy().argmax()])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "NUM_CLASSES = len(class_names)\n",
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Random data augmentation: flipping + rotation to compensate small image dataset\n",
    "data_augmentation = keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"), \n",
    "    tf.keras.layers.RandomRotation(0.1), # randomly rotates counter clock-wise 10% of 360° (i.e. 36°)\n",
    "])\n",
    "\n",
    "# 1. Create a base pre-trained model with tf.keras.applications\n",
    "# include_top=False: Do not include the MobileNetV2 classifier at the top.\n",
    "base_model = tf.keras.applications.MobileNetV3Large(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# 2. Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into models\n",
    "inputs = tf.keras.layers.Input(shape =(IMG_HEIGHT, IMG_WIDTH, 3), name=\"input-layer\")\n",
    "\n",
    "# 4. Preprocessing: Only for training, during inference time, the output will be identical to input.\n",
    "# Apply random data augmentation\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# 5. Preprocessing according to pre-trained model: inputs pixel values are scaled between -1 and 1\n",
    "# will also be applied during inference time (i.e. when used to predict)\n",
    "x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs) #x\n",
    "\n",
    "# 6. Pass the inputs\n",
    "x = base_model(x)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 7. Average pool the outputs of the base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "# 8. Regularize with dropout (only while training applied)\n",
    "#x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# 9. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"output-layer\")(x)\n",
    "\n",
    "# 10. Combine the inputs with outputs into a model\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n",
    "    metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and track with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# https://www.mlflow.org/docs/latest/tracking.html#performance-tracking-with-metrics\n",
    "with mlflow.start_run(run_name='MobileNetV3L'):\n",
    "    run = mlflow.active_run()\n",
    "\n",
    "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        #steps_per_epoch = len(train_ds),\n",
    "        #validation_steps = int(0.25*len(val_ds)),\n",
    "        callbacks=train_callbacks\n",
    "    )\n",
    "\n",
    "    #seting parameters that should be logged on MLFlow\n",
    "    #these parameters were used in feature engineering (inputing missing values)\n",
    "    #or parameters of the model (fit_intercept for Linear Regression model)\n",
    "    params = {\n",
    "        \"dataset\": DATASET,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"image_size\": IMG_HEIGHT,\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "    }\n",
    "\n",
    "    #logging params to mlflow\n",
    "    mlflow.log_params(params)\n",
    "    #setting tags\n",
    "    mlflow.set_tag(\"running_from_jupyter\", \"True\")\n",
    "\n",
    "    #logging metrics\n",
    "    for epoch in range(0, NUM_EPOCHS):\n",
    "        mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"valid-\" + \"accuracy\", history.history['val_accuracy'][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"valid-\" + \"loss\", history.history['val_loss'][epoch], step=epoch)\n",
    "\n",
    "    # logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "    # but possible if running mlflow locally\n",
    "    # mlflow.log_artifact(\"../models\")\n",
    "    # mlflow.sklearn.log_model(reg, \"model\")\n",
    "    #mlflow.keras.log_model(model_p100_e2 ,'InceptionV3')\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is taken from [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "\n",
    "  loss = history.history[\"loss\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "  accuracy = history.history[\"accuracy\"]\n",
    "  val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "  epochs = range(len(history.history[\"loss\"]))\n",
    "\n",
    "  #plot loss\n",
    "  plt.plot(epochs, loss, label = \"training_loss\")\n",
    "  plt.plot(epochs, val_loss, label = \"val_loss\")\n",
    "  plt.title(\"loss\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()\n",
    "\n",
    "  #plot accuracy\n",
    "  plt.figure() \n",
    "  plt.plot(epochs, accuracy, label = \"training_accuracy\")\n",
    "  plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n",
    "  plt.title(\"accuracy\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Save model, history and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "\n",
    "if SAVE == True:\n",
    "    # Save the entire model as a SavedModel.\n",
    "    #!mkdir -p saved_model\n",
    "\n",
    "    # make new folder 'saved_model' if it does not already exist\n",
    "    if not os.path.isdir(path + '/saved_model'):\n",
    "        os.makedirs(path + '/saved_model')\n",
    "\n",
    "    model_name = 'MobileNetV2_Kaggle_p' + str(IMG_HEIGHT) + '_e ' + str(NUM_EPOCHS)\n",
    "    #model.save(path + '/saved_model/' + model_name)\n",
    "\n",
    "    # save history\n",
    "    with open(path + '/saved_model/' + model_name + '/trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    # assemble model parameters\n",
    "    param_dict = {}\n",
    "    param_dict['ds'] = DATASET\n",
    "    param_dict['lr'] = LEARNING_RATE\n",
    "    param_dict['bs'] = BATCH_SIZE\n",
    "    param_dict['eps'] = NUM_EPOCHS\n",
    "    param_dict['img_height'] = IMG_HEIGHT\n",
    "\n",
    "    # save model parameters\n",
    "    with open(path + '/saved_model/' + model_name + '/trainParamsDict', 'wb') as file_pi:\n",
    "        pickle.dump(param_dict, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble model parameters\n",
    "param_dict = {}\n",
    "param_dict['ds'] = DATASET\n",
    "param_dict['lr'] = LEARNING_RATE\n",
    "param_dict['bs'] = BATCH_SIZE\n",
    "param_dict['eps'] = NUM_EPOCHS\n",
    "param_dict['img_height'] = IMG_HEIGHT\n",
    "\n",
    "# save model parameters\n",
    "with open(path + '/saved_model/' + model_name + '/trainParamsDict', 'wb') as file_pi:\n",
    "    pickle.dump(param_dict, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Retrain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example, see https://keras.io/api/applications/ at the bottom **Fine-tune InceptionV3 on a new set of classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze top layers of Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To begin fine-tuning lets start by setting the last 10 layers as trainable\n",
    "base_model.trainable = True\n",
    "\n",
    "# Un-freeze last 10 layers\n",
    "for layer in base_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile (we have to compile model every time there is a change)\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1*LEARNING_RATE), # when fine-tuning you typically want to lower lr by 10x\n",
    "        metrics = [\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which layers are trainable\n",
    "for layer_number, layer in enumerate(base_model.layers):\n",
    "    print(layer_number, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have unfrozen some of the layers on the top \n",
    "print(len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning and Refitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = history.epoch[-1] + 10\n",
    "\n",
    "# Refit the model\n",
    "history_2 = model.fit(train_ds,\n",
    "                       epochs = fine_tune_epochs,\n",
    "                       validation_data = val_ds,\n",
    "                       #validation_steps = int(0.25*len(val_data)),\n",
    "                       initial_epoch =  history.epoch[-1],) # Start the epoch where it left before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Making some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is taken from [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that preprocess the custom data\n",
    "def load_and_prep_image(filename, img_shape = IMG_HEIGHT):\n",
    "  img = tf.io.read_file(filename) #read image\n",
    "  img_original = mpimg.imread(filename)\n",
    "  img = tf.image.decode_image(img) # decode the image to a tensor\n",
    "  img = tf.image.resize(img, size = [img_shape, img_shape]) # resize the image\n",
    "  #img = (img/127.5)-1 # rescale the image to range [-1,1]   maybe unneccessary, as rescaling is part of the model itself? see step 4\n",
    "  return img, img_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot(model, filename, class_names):\n",
    "  \"\"\"\n",
    "  Imports an image located at filename, makes a prediction on it with\n",
    "  a trained model and plots the image with the predicted class as the title.\n",
    "  \"\"\"\n",
    "  # Import the target image and preprocess it\n",
    "  img, img_original = load_and_prep_image(filename)\n",
    "\n",
    "  # Make a prediction\n",
    "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "  # Get the predicted class\n",
    "  if len(pred[0]) > 1: # check for multi-class\n",
    "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
    "  else:\n",
    "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
    "\n",
    "  # Plot the image and predicted class\n",
    "  plt.imshow(img_original)\n",
    "  plt.title(f\"Prediction: {pred_class}\")\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsel = path + '/data/data_2/images to test/Amsel.jpeg'\n",
    "blaumeise = path + '/data/data_2/images to test/blaumeise.jpeg'\n",
    "buchfink = path + '/data/data_2/images to test/buchfink.jpeg'\n",
    "elster = path + '/data/data_2/images to test/elster.jpeg'\n",
    "feldsperling = path + '/data/data_2/images to test/feldsperling.jpeg'\n",
    "firefinch = path + '/data/data_2/images to test/firefinch.jpg'\n",
    "gruenfink = path + '/data/data_2/images to test/grünfink.jpeg'\n",
    "haussperling = path + '/data/data_2/images to test/haussperling.jpeg'\n",
    "kohlmeise = path + '/data/data_2/images to test/Kohlmeise.jpeg'\n",
    "mauersegler = path + '/data/data_2/images to test/mauersegler.jpeg'\n",
    "mehlschwalbe = path + '/data/data_2/images to test/mehlschwalbe.jpeg'\n",
    "rotkehlchen = path + '/data/data_2/images to test/Rotkehlchen.jpeg'\n",
    "star = path + '/data/data_2/images to test/Star.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amsel - blackbird\n",
    "pred_and_plot(model,amsel, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blaumeise - Eurasian blue tit\n",
    "pred_and_plot(model,blaumeise, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buchfink - common chaffinch\n",
    "pred_and_plot(model,buchfink, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elster - Eurasien magpie\n",
    "pred_and_plot(model,elster, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feldsperling - Eurasian tree sparrow\n",
    "pred_and_plot(model,feldsperling, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firefinch - \n",
    "pred_and_plot(model,firefinch, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gruenfink - European greenfinch\n",
    "pred_and_plot(model,gruenfink, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haussperling - house sparrow\n",
    "pred_and_plot(model,haussperling, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kohlmeise - Great tit\n",
    "pred_and_plot(model,kohlmeise, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mauersegler - Common Swift\n",
    "pred_and_plot(model,mauersegler, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mehlschwalbe - Common House Martin\n",
    "pred_and_plot(model,mehlschwalbe, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotkehlchen - European Robin\n",
    "pred_and_plot(model,rotkehlchen, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star - common starling\n",
    "pred_and_plot(model,star, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99cf74314b42ac8a8c1da03c92f17d43111865473f1a5aa1cc3b81d76b6237d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
